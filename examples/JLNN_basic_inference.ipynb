{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RadimKozl/JLNN/blob/main/examples/JLNN_basic_inference.ipynb)"
      ],
      "metadata": {
        "id": "M3x8ZyidlKx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **JLNN â€“ Basic inference + manual grounding**\n",
        "\n",
        "This notebook shows the simplest use of the JLNN framework:\n",
        "\n",
        "- Definition of a logical rule without training\n",
        "- Manual setting of truth intervals [L, U] for each predicate\n",
        "- Calculation of the output interval for the entire rule\n",
        "- Display of the uncertainty width (U - L)"
      ],
      "metadata": {
        "id": "3SVjAr7DKZRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Installation and automatic restart***"
      ],
      "metadata": {
        "id": "7f3KhYwQNDl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import jlnn\n",
        "    from flax import nnx\n",
        "    import jax.numpy as jnp\n",
        "    print(\"âœ… JLNN and JAX are ready.\")\n",
        "except ImportError:\n",
        "    print(\"ğŸš€ Installing JLNN from GitHub and fixing JAX for Colab...\")\n",
        "    # Instalace frameworku\n",
        "    !pip install jax-lnn --quiet\n",
        "    # Fix JAX/CUDA compatibility for 2026 in Colab\n",
        "    !pip install --upgrade \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "\n",
        "    import os\n",
        "    print(\"\\nğŸ”„ RESTARTING ENVIRONMENT... Please wait a second and then run the cell again.\")\n",
        "    os.kill(os.getpid(), 9)\n",
        "    os.kill(os.getpid(), 9) # After this line, the cell stops and the environment restarts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SW8QAXiJ93Y",
        "outputId": "724d942d-a58c-4f7c-bddc-1aab2b04e654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Installing JLNN from GitHub and fixing JAX for Colab...\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m488.0/488.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.3/80.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m915.7/915.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m842.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.1/139.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for orbax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.2 which is incompatible.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.10.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.2 which is incompatible.\n",
            "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Requirement already satisfied: jax[cuda12_pip] in /usr/local/lib/python3.12/dist-packages (0.9.0.1)\n",
            "\u001b[33mWARNING: jax 0.9.0.1 does not provide the extra 'cuda12-pip'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: jaxlib<=0.9.0.1,>=0.9.0.1 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (0.9.0.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (0.5.4)\n",
            "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (2.4.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (1.16.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAX_PLATFORMS\"] = \"cpu\""
      ],
      "metadata": {
        "id": "D7fYLlV5KXcx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Imports***"
      ],
      "metadata": {
        "id": "7evtGjniB0Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from flax import nnx\n",
        "from jlnn.symbolic.compiler import LNNFormula"
      ],
      "metadata": {
        "id": "NxN9UB0eB4Dr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"JLNN loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml5NkCe8CSPH",
        "outputId": "21db7963-8d50-4a05-9298-db622232a1e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JLNN loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Definition of a simple rule***\n",
        "\n",
        "We will use the classic rule:\n",
        "\n",
        "```python\n",
        "0.8::A & B -> C\n",
        "```\n",
        "\n",
        "- Rule weight 0.8 (confidence in implication)\n",
        "- A âˆ§ B implies C\n",
        "- No weighted antecedent or temporal operator (yet)"
      ],
      "metadata": {
        "id": "o14d9UGyCpC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***model creation***"
      ],
      "metadata": {
        "id": "S3HRyVykEmGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model creation â€“ compiling rules into an NNX graph\n",
        "model = LNNFormula(\"0.8::A & B -> C\", nnx.Rngs(42))"
      ],
      "metadata": {
        "id": "KS1znTDcG3l9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model created. Predicates:\", list(model.predicates.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDJSMHKnHRyj",
        "outputId": "45fc4749-c525-4286-f7de-de6da921a694"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model created. Predicates: ['A', 'B', 'C']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***3. Manual grounding â€“ setting intervals***\n",
        "\n",
        "Each predicate (A, B, C) gets a **manual truth interval [L, U]**.\n",
        "\n",
        "- L = lower bound (minimum confirmed truth)\n",
        "- U = upper bound (maximum possible truth)\n",
        "- Width of the interval U - L = degree of uncertainty/ignorance\n",
        "\n",
        "### ***interval setting + inference***\n",
        "\n",
        "Manually set intervals for each predicate <br>\n",
        "Format: [L, U] for batch size 1"
      ],
      "metadata": {
        "id": "GMQWnXupJahD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"A\": jnp.array([[0.7, 0.9]]),   # And it is quite likely\n",
        "    \"B\": jnp.array([[0.4, 0.8]]),   # B has more uncertainty\n",
        "    \"C\": jnp.array([[0.0, 1.0]])    # C is completely unknown (ignorance)\n",
        "}"
      ],
      "metadata": {
        "id": "AiA3qbq3JeXd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output interval for C"
      ],
      "metadata": {
        "id": "4cIzM5EUL9ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(inputs)"
      ],
      "metadata": {
        "id": "pr72XN8_MDgt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will find out the shape and adjust the approach"
      ],
      "metadata": {
        "id": "9IsJNWLCVL2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmSlZL0GVTpM",
        "outputId": "07a44c6f-d86e-4dac-bcf3-ea240df11eda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (1, 2, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the batch dimension is (usually the first), we take the first sample"
      ],
      "metadata": {
        "id": "Ad3tmUKDWJu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len(output.shape) == 3:          # (batch, 1, 2) or similar\n",
        "    L = output[0, 0, 0].item()\n",
        "    U = output[0, 0, 1].item()\n",
        "elif len(output.shape) == 2:        # (batch, 2)\n",
        "    L = output[0, 0].item()\n",
        "    U = output[0, 1].item()\n",
        "elif len(output.shape) == 1:        # only (2,)\n",
        "    L = output[0].item()\n",
        "    U = output[1].item()\n",
        "else:\n",
        "    raise ValueError(f\"Unknown output shape: {output.shape}\")"
      ],
      "metadata": {
        "id": "RMbfBt9zWjQE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Output interval for C:\")\n",
        "print(f\"  L = {L:.4f}\")\n",
        "print(f\"  U = {U:.4f}\")\n",
        "print(f\"  Uncertainty (width): {U - L:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPoaxIPuWslk",
        "outputId": "42c9633d-03b3-4522-eb18-8e75ef0367e6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output interval for C:\n",
            "  L = 0.6000\n",
            "  U = 0.7000\n",
            "  Uncertainty (width): 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Experiments â€“ different input intervals***\n",
        "\n",
        "Try changing the values â€‹â€‹and running the cell again.\n",
        "What happens if:\n",
        "\n",
        "- A and B have high L (e.g. [0.9, 1.0]) â†’ C should have high L\n",
        "- A has low U (e.g. [0.0, 0.2]) â†’ C will be low\n",
        "- One of the antecedents has high uncertainty â†’ uncertainty is transferred to C\n",
        "\n",
        "### ***second set of experiments***"
      ],
      "metadata": {
        "id": "_E2dhRRKM57u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 1: both antecedents strongly true"
      ],
      "metadata": {
        "id": "IGn4bop_QIOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_exp1 = {\n",
        "    \"A\": jnp.array([[0.95, 1.0]]),\n",
        "    \"B\": jnp.array([[0.90, 0.98]]),\n",
        "    \"C\": jnp.array([[0.0, 1.0]])\n",
        "}\n",
        "print(\"Exp 1 â€“ strong A and B:\")\n",
        "print(model(inputs_exp1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGoWBAf7OZUL",
        "outputId": "a344ad5e-8fe3-42e2-de28-a8eeefc9a7bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exp 1 â€“ strong A and B:\n",
            "[[[0.5 0.7]\n",
            "  [1.  1. ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 2: one antecedent weak"
      ],
      "metadata": {
        "id": "oeRn9TO4Qba1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_exp2 = {\n",
        "    \"A\": jnp.array([[0.95, 1.0]]),\n",
        "    \"B\": jnp.array([[0.1, 0.3]]),\n",
        "    \"C\": jnp.array([[0.0, 1.0]])\n",
        "}\n",
        "print(\"\\nExp 2 â€“ weak B:\")\n",
        "print(model(inputs_exp2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go6z5AefP8_l",
        "outputId": "d2e96ba6-bcc1-4164-be40-a29938301c88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exp 2 â€“ weak B:\n",
            "[[[0.9 0.9]\n",
            "  [1.  1. ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 3: high uncertainty in A"
      ],
      "metadata": {
        "id": "nu4XCs38Qm6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_exp3 = {\n",
        "    \"A\": jnp.array([[0.4, 0.9]]),\n",
        "    \"B\": jnp.array([[0.8, 0.95]]),\n",
        "    \"C\": jnp.array([[0.0, 1.0]])\n",
        "}\n",
        "print(\"\\nExp 3 â€“ high uncertainty in A:\")\n",
        "print(model(inputs_exp3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0716SrDQDBH",
        "outputId": "f27500fc-85d0-47fa-f3a0-390dd34760a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exp 3 â€“ high uncertainty in A:\n",
            "[[[0.6 0.7]\n",
            "  [1.  1. ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Summary***\n",
        "\n",
        "- JLNN converts symbolic rules to a differentiable NNX graph\n",
        "- Inference returns the interval [L, U] â€“ not just one value\n",
        "- Width of U - L shows the degree of uncertainty / ignorance\n",
        "- No model parameters were trained â€“ everything is manual"
      ],
      "metadata": {
        "id": "phK9JFYfRT31"
      }
    }
  ]
}