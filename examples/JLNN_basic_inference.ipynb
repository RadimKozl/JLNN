{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RadimKozl/JLNN/blob/main/examples/JLNN_basic_inference.ipynb)"
      ],
      "metadata": {
        "id": "M3x8ZyidlKx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **JLNN â€“ Basic inference + manual grounding**\n",
        "\n",
        "This notebook shows the simplest use of the JLNN framework:\n",
        "\n",
        "- Definition of a logical rule without training\n",
        "- Manual setting of truth intervals [L, U] for each predicate\n",
        "- Calculation of the output interval for the entire rule\n",
        "- Display of the uncertainty width (U - L)"
      ],
      "metadata": {
        "id": "3SVjAr7DKZRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Installation and automatic restart***"
      ],
      "metadata": {
        "id": "7f3KhYwQNDl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import jlnn\n",
        "    from flax import nnx\n",
        "    import jax.numpy as jnp\n",
        "    print(\"âœ… JLNN and JAX are ready.\")\n",
        "except ImportError:\n",
        "    print(\"ğŸš€ Installing JLNN from GitHub and fixing JAX for Colab...\")\n",
        "    # Instalace frameworku\n",
        "    #!pip install jax-lnn --quiet\n",
        "    !pip install git+https://github.com/RadimKozl/JLNN.git\n",
        "    # Fix JAX/CUDA compatibility for 2026 in Colab\n",
        "    !pip install --upgrade \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "\n",
        "    import os\n",
        "    print(\"\\nğŸ”„ RESTARTING ENVIRONMENT... Please wait a second and then run the cell again.\")\n",
        "    os.kill(os.getpid(), 9)\n",
        "    os.kill(os.getpid(), 9) # After this line, the cell stops and the environment restarts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1SW8QAXiJ93Y",
        "outputId": "56fb3a9b-8648-4f1d-8919-9f28f70d4409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Installing JLNN from GitHub and fixing JAX for Colab...\n",
            "Collecting git+https://github.com/RadimKozl/JLNN.git\n",
            "  Cloning https://github.com/RadimKozl/JLNN.git to /tmp/pip-req-build-v84n1p10\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/RadimKozl/JLNN.git /tmp/pip-req-build-v84n1p10\n",
            "  Resolved https://github.com/RadimKozl/JLNN.git to commit d9d3527ccfb41600a5e5916b50a53b9715707927\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flax>=0.12.2 (from jax-lnn==0.1rc1)\n",
            "  Downloading flax-0.12.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jax>=0.8.2 (from jax-lnn==0.1rc1)\n",
            "  Downloading jax-0.9.0.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib>=0.8.2 (from jax-lnn==0.1rc1)\n",
            "  Downloading jaxlib-0.9.0.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: lark>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from jax-lnn==0.1rc1) (1.3.1)\n",
            "Collecting matplotlib>=3.10.8 (from jax-lnn==0.1rc1)\n",
            "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=3.6.1 in /usr/local/lib/python3.12/dist-packages (from jax-lnn==0.1rc1) (3.6.1)\n",
            "Collecting numpy>=2.4.1 (from jax-lnn==0.1rc1)\n",
            "  Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting onnx>=1.20.1 (from jax-lnn==0.1rc1)\n",
            "  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting onnx2pytorch>=0.5.3 (from jax-lnn==0.1rc1)\n",
            "  Downloading onnx2pytorch-0.5.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting onnxruntime>=1.23.2 (from jax-lnn==0.1rc1)\n",
            "  Downloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: optax>=0.2.6 in /usr/local/lib/python3.12/dist-packages (from jax-lnn==0.1rc1) (0.2.6)\n",
            "Collecting orbax>=0.1.9 (from jax-lnn==0.1rc1)\n",
            "  Downloading orbax-0.1.9.tar.gz (1.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from jax-lnn==0.1rc1) (0.13.2)\n",
            "Collecting torch>=2.10.0 (from jax-lnn==0.1rc1)\n",
            "  Downloading torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (31 kB)\n",
            "Requirement already satisfied: xarray>=2025.12.0 in /usr/local/lib/python3.12/dist-packages (from jax-lnn==0.1rc1) (2025.12.0)\n",
            "INFO: pip is looking at multiple versions of flax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting flax>=0.12.2 (from jax-lnn==0.1rc1)\n",
            "  Downloading flax-0.12.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1rc1) (1.1.2)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1rc1) (0.11.32)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1rc1) (0.1.80)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1rc1) (13.9.4)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1rc1) (4.15.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1rc1) (6.0.3)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1rc1) (0.1.10)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.2->jax-lnn==0.1rc1) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.2->jax-lnn==0.1rc1) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.2->jax-lnn==0.1rc1) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1rc1) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1rc1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1rc1) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1rc1) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1rc1) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1rc1) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1rc1) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1rc1) (2.9.0.post0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.20.1->jax-lnn==0.1rc1) (5.29.5)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from onnx2pytorch>=0.5.3->jax-lnn==0.1rc1) (0.24.0+cpu)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.23.2->jax-lnn==0.1rc1) (25.12.19)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.23.2->jax-lnn==0.1rc1) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from optax>=0.2.6->jax-lnn==0.1rc1) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.12/dist-packages (from optax>=0.2.6->jax-lnn==0.1rc1) (0.1.90)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn>=0.13.2->jax-lnn==0.1rc1) (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.10.0->jax-lnn==0.1rc1) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.10.0->jax-lnn==0.1rc1) (75.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.10.0->jax-lnn==0.1rc1) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.10.0->jax-lnn==0.1rc1) (2025.3.0)\n",
            "Collecting cuda-bindings==12.9.4 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.4.5 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.6.0 (from torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting cuda-pathfinder~=1.1 (from cuda-bindings==12.9.4->torch>=2.10.0->jax-lnn==0.1rc1)\n",
            "  Downloading cuda_pathfinder-1.3.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.87->optax>=0.2.6->jax-lnn==0.1rc1) (0.12.1)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1rc1) (1.13.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1rc1) (1.6.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1rc1) (24.1.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1rc1) (4.15.0)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1rc1) (3.20.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1rc1) (5.9.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn>=0.13.2->jax-lnn==0.1rc1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn>=0.13.2->jax-lnn==0.1rc1) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.10.8->jax-lnn==0.1rc1) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax>=0.12.2->jax-lnn==0.1rc1) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax>=0.12.2->jax-lnn==0.1rc1) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.23.2->jax-lnn==0.1rc1) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision>=0.9.0 (from onnx2pytorch>=0.5.3->jax-lnn==0.1rc1)\n",
            "  Downloading torchvision-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.10.0->jax-lnn==0.1rc1) (3.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.12.2->jax-lnn==0.1rc1) (0.1.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1rc1) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1rc1) (3.23.0)\n",
            "Downloading flax-0.12.2-py3-none-any.whl (488 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m488.0/488.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.9.0.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.9.0.1-cp312-cp312-manylinux_2_27_x86_64.whl (80.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.3/80.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx2pytorch-0.5.3-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (915.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m915.7/915.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (139.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.1/139.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cuda_pathfinder-1.3.3-py3-none-any.whl (27 kB)\n",
            "Building wheels for collected packages: jax-lnn, orbax\n",
            "  Building wheel for jax-lnn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax-lnn: filename=jax_lnn-0.1rc1-py3-none-any.whl size=53819 sha256=b3cef1fe16f877c10b57afb5ec515af81b8f8fbeb91f0bba73766ab56465038e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eivn0w68/wheels/e4/73/e2/53d463a119e4252930e9bea05cfd1d7013a414201220cab8a8\n",
            "  Building wheel for orbax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for orbax: filename=orbax-0.1.9-py3-none-any.whl size=1496 sha256=62ba55384836d8e550d0dc39176d320707f216c890ad78f6241c1e61f92f2b4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/93/1e/1d353609083480a258a14db334d1c16aefa65d30440035b8fd\n",
            "Successfully built jax-lnn orbax\n",
            "Installing collected packages: nvidia-cusparselt-cu12, triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, cuda-pathfinder, onnxruntime, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, cuda-bindings, onnx, nvidia-cusolver-cu12, matplotlib, jaxlib, torch, jax, torchvision, orbax, onnx2pytorch, flax, jax-lnn\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.29.2\n",
            "    Uninstalling nvidia-nccl-cu12-2.29.2:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.29.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.7.2\n",
            "    Uninstalling jaxlib-0.7.2:\n",
            "      Successfully uninstalled jaxlib-0.7.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cpu\n",
            "    Uninstalling torch-2.9.0+cpu:\n",
            "      Successfully uninstalled torch-2.9.0+cpu\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.7.2\n",
            "    Uninstalling jax-0.7.2:\n",
            "      Successfully uninstalled jax-0.7.2\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cpu\n",
            "    Uninstalling torchvision-0.24.0+cpu:\n",
            "      Successfully uninstalled torchvision-0.24.0+cpu\n",
            "  Attempting uninstall: flax\n",
            "    Found existing installation: flax 0.11.2\n",
            "    Uninstalling flax-0.11.2:\n",
            "      Successfully uninstalled flax-0.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.2 which is incompatible.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.10.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.2 which is incompatible.\n",
            "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cuda-bindings-12.9.4 cuda-pathfinder-1.3.3 flax-0.12.2 jax-0.9.0.1 jax-lnn-0.1rc1 jaxlib-0.9.0.1 matplotlib-3.10.8 numpy-2.4.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.4.5 nvidia-nvtx-cu12-12.8.90 onnx-1.20.1 onnx2pytorch-0.5.3 onnxruntime-1.24.1 orbax-0.1.9 torch-2.10.0 torchvision-0.25.0 triton-3.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              },
              "id": "2c6748572ab24445a4af54f6e95fbc8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Requirement already satisfied: jax[cuda12_pip] in /usr/local/lib/python3.12/dist-packages (0.9.0.1)\n",
            "\u001b[33mWARNING: jax 0.9.0.1 does not provide the extra 'cuda12-pip'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: jaxlib<=0.9.0.1,>=0.9.0.1 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (0.9.0.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (0.5.4)\n",
            "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (2.4.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (1.16.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAX_PLATFORMS\"] = \"cpu\""
      ],
      "metadata": {
        "id": "D7fYLlV5KXcx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Imports***"
      ],
      "metadata": {
        "id": "7evtGjniB0Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from flax import nnx\n",
        "from jlnn.symbolic.compiler import LNNFormula"
      ],
      "metadata": {
        "id": "NxN9UB0eB4Dr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"JLNN loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml5NkCe8CSPH",
        "outputId": "b006a969-8cb7-42f4-a7e8-7c0bf10b9bdd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JLNN loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Definition of a simple rule***\n",
        "\n",
        "We will use the classic rule:\n",
        "\n",
        "```python\n",
        "0.8::A & B -> C\n",
        "```\n",
        "\n",
        "- Rule weight 0.8 (confidence in implication)\n",
        "- A âˆ§ B implies C\n",
        "- No weighted antecedent or temporal operator (yet)"
      ],
      "metadata": {
        "id": "o14d9UGyCpC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***model creation***"
      ],
      "metadata": {
        "id": "S3HRyVykEmGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model creation â€“ compiling rules into an NNX graph\n",
        "model = LNNFormula(\"0.8::A & B -> C\", nnx.Rngs(42))"
      ],
      "metadata": {
        "id": "KS1znTDcG3l9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model created. Predicates:\", list(model.predicates.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDJSMHKnHRyj",
        "outputId": "2b38134c-89be-4c88-e24c-d477ef8c08f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model created. Predicates: ['A', 'B', 'C']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***3. Manual grounding â€“ setting intervals***\n",
        "\n",
        "Each predicate (A, B, C) gets a **manual truth interval [L, U]**.\n",
        "\n",
        "- L = lower bound (minimum confirmed truth)\n",
        "- U = upper bound (maximum possible truth)\n",
        "- Width of the interval U - L = degree of uncertainty/ignorance\n",
        "\n",
        "### ***interval setting + inference***\n",
        "\n",
        "Manually set intervals for each predicate <br>\n",
        "Format: [L, U] for batch size 1"
      ],
      "metadata": {
        "id": "GMQWnXupJahD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"A\": jnp.array([[0.7, 0.9]]),   # And it is quite likely\n",
        "    \"B\": jnp.array([[0.4, 0.8]]),   # B has more uncertainty\n",
        "    \"C\": jnp.array([[0.0, 1.0]])    # C is completely unknown (ignorance)\n",
        "}"
      ],
      "metadata": {
        "id": "AiA3qbq3JeXd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output interval for C"
      ],
      "metadata": {
        "id": "4cIzM5EUL9ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(inputs)"
      ],
      "metadata": {
        "id": "pr72XN8_MDgt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will find out the shape and adjust the approach"
      ],
      "metadata": {
        "id": "9IsJNWLCVL2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmSlZL0GVTpM",
        "outputId": "84fc68a4-48fb-4123-ab95-cf257499f544"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (1, 2, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the batch dimension is (usually the first), we take the first sample"
      ],
      "metadata": {
        "id": "Ad3tmUKDWJu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len(output.shape) == 3:          # (batch, 1, 2) or similar\n",
        "    L = output[0, 0, 0].item()\n",
        "    U = output[0, 0, 1].item()\n",
        "elif len(output.shape) == 2:        # (batch, 2)\n",
        "    L = output[0, 0].item()\n",
        "    U = output[0, 1].item()\n",
        "elif len(output.shape) == 1:        # only (2,)\n",
        "    L = output[0].item()\n",
        "    U = output[1].item()\n",
        "else:\n",
        "    raise ValueError(f\"Unknown output shape: {output.shape}\")"
      ],
      "metadata": {
        "id": "RMbfBt9zWjQE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Output interval for C:\")\n",
        "print(f\"  L = {L:.4f}\")\n",
        "print(f\"  U = {U:.4f}\")\n",
        "print(f\"  Uncertainty (width): {U - L:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPoaxIPuWslk",
        "outputId": "b900a513-dd91-4e71-c533-5695901b1c1b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output interval for C:\n",
            "  L = 0.5000\n",
            "  U = 0.8000\n",
            "  Uncertainty (width): 0.3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Experiments â€“ different input intervals***\n",
        "\n",
        "Try changing the values â€‹â€‹and running the cell again.\n",
        "What happens if:\n",
        "\n",
        "- A and B have high L (e.g. [0.9, 1.0]) â†’ C should have high L\n",
        "- A has low U (e.g. [0.0, 0.2]) â†’ C will be low\n",
        "- One of the antecedents has high uncertainty â†’ uncertainty is transferred to C\n",
        "\n",
        "### ***second set of experiments***"
      ],
      "metadata": {
        "id": "_E2dhRRKM57u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 1: both antecedents strongly true"
      ],
      "metadata": {
        "id": "IGn4bop_QIOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_exp1 = {\n",
        "    \"A\": jnp.array([[0.95, 1.0]]),\n",
        "    \"B\": jnp.array([[0.90, 0.98]]),\n",
        "    \"C\": jnp.array([[0.0, 1.0]])\n",
        "}\n",
        "print(\"Exp 1 â€“ strong A and B:\")\n",
        "print(model(inputs_exp1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGoWBAf7OZUL",
        "outputId": "b31637db-8131-4b58-8d7f-f1baa8ae5714"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exp 1 â€“ strong A and B:\n",
            "[[[0.5 0.7]\n",
            "  [1.  1. ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 2: one antecedent weak"
      ],
      "metadata": {
        "id": "oeRn9TO4Qba1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_exp2 = {\n",
        "    \"A\": jnp.array([[0.95, 1.0]]),\n",
        "    \"B\": jnp.array([[0.1, 0.3]]),\n",
        "    \"C\": jnp.array([[0.0, 1.0]])\n",
        "}\n",
        "print(\"\\nExp 2 â€“ weak B:\")\n",
        "print(model(inputs_exp2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go6z5AefP8_l",
        "outputId": "11f1d8d8-edd8-461c-f20d-c70b903e91d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exp 2 â€“ weak B:\n",
            "[[[0.7 1. ]\n",
            "  [1.  1. ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 3: high uncertainty in A"
      ],
      "metadata": {
        "id": "nu4XCs38Qm6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_exp3 = {\n",
        "    \"A\": jnp.array([[0.4, 0.9]]),\n",
        "    \"B\": jnp.array([[0.8, 0.95]]),\n",
        "    \"C\": jnp.array([[0.0, 1.0]])\n",
        "}\n",
        "print(\"\\nExp 3 â€“ high uncertainty in A:\")\n",
        "print(model(inputs_exp3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0716SrDQDBH",
        "outputId": "7038ae77-99c9-4608-e57e-78da4d40905d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exp 3 â€“ high uncertainty in A:\n",
            "[[[0.5 0.8]\n",
            "  [1.  1. ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Summary***\n",
        "\n",
        "- JLNN converts symbolic rules to a differentiable NNX graph\n",
        "- Inference returns the interval [L, U] â€“ not just one value\n",
        "- Width of U - L shows the degree of uncertainty / ignorance\n",
        "- No model parameters were trained â€“ everything is manual"
      ],
      "metadata": {
        "id": "phK9JFYfRT31"
      }
    }
  ]
}