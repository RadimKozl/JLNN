{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RadimKozl/JLNN/blob/main/examples/Jax_lnn_base.ipynb)"
      ],
      "metadata": {
        "id": "INrGNlBJ_Lzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **JLNN â€“ JAX Logical Neural Networks â€“ Introductory example**\n",
        "-----------------------------------------------------------------\n",
        "\n",
        "This notebook shows the basic usage of the JLNN framework:\n",
        "- Installation directly from GitHub\n",
        "- Definition of a simple rule `0.8::A & B -> C`\n",
        "- Grounding predicates on data\n",
        "- Training with MSE + contradiction loss\n",
        "- Saving and loading a checkpoint with structure check\n",
        "\n",
        "**Note:** Training is stable, NaN-free, with convergence to the target interval."
      ],
      "metadata": {
        "id": "vzGkORPVEduy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. INSTALLATION AND AUTOMATIC RESTART***\n",
        "\n",
        "In Google Colab, you just need to install the package directly from GitHub. Since the export tools are built-in, no extra parameters are needed."
      ],
      "metadata": {
        "id": "LWt4IoJFs1nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import jlnn\n",
        "    from flax import nnx\n",
        "    import jax.numpy as jnp\n",
        "    print(\"âœ… JLNN and JAX are ready.\")\n",
        "except ImportError:\n",
        "    print(\"ğŸš€ Installing JLNN from GitHub and fixing JAX for Colab...\")\n",
        "    # Instalace frameworku\n",
        "    !pip install git+https://github.com/RadimKozl/JLNN.git\n",
        "    # Fix JAX/CUDA compatibility for 2026 in Colab\n",
        "    !pip install --upgrade \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "\n",
        "    import os\n",
        "    print(\"\\nğŸ”„ RESTARTING ENVIRONMENT... Please wait a second and then run the cell again.\")\n",
        "    os.kill(os.getpid(), 9)\n",
        "    os.kill(os.getpid(), 9) # After this line, the cell stops and the environment restarts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ituotx3CzH19",
        "outputId": "52a305ac-02b5-44b9-b9d2-d376a76d67b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Installing JLNN from GitHub and fixing JAX for Colab...\n",
            "Collecting git+https://github.com/RadimKozl/JLNN.git\n",
            "  Cloning https://github.com/RadimKozl/JLNN.git to /tmp/pip-req-build-w0ma759x\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/RadimKozl/JLNN.git /tmp/pip-req-build-w0ma759x\n",
            "  Resolved https://github.com/RadimKozl/JLNN.git to commit bb5667fccf8d6fa77cf68cea16f7cdd9494cb346\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flax>=0.12.2 (from jax-lnn==0.1.0)\n",
            "  Downloading flax-0.12.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jax>=0.8.2 (from jax-lnn==0.1.0)\n",
            "  Downloading jax-0.9.0.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib>=0.8.2 (from jax-lnn==0.1.0)\n",
            "  Downloading jaxlib-0.9.0.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: lark>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from jax-lnn==0.1.0) (1.3.1)\n",
            "Collecting matplotlib>=3.10.8 (from jax-lnn==0.1.0)\n",
            "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=3.6.1 in /usr/local/lib/python3.12/dist-packages (from jax-lnn==0.1.0) (3.6.1)\n",
            "Collecting numpy>=2.4.1 (from jax-lnn==0.1.0)\n",
            "  Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting onnx>=1.20.1 (from jax-lnn==0.1.0)\n",
            "  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting onnx2pytorch>=0.5.3 (from jax-lnn==0.1.0)\n",
            "  Downloading onnx2pytorch-0.5.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting onnxruntime>=1.23.2 (from jax-lnn==0.1.0)\n",
            "  Downloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: optax>=0.2.6 in /usr/local/lib/python3.12/dist-packages (from jax-lnn==0.1.0) (0.2.6)\n",
            "Collecting orbax>=0.1.9 (from jax-lnn==0.1.0)\n",
            "  Downloading orbax-0.1.9.tar.gz (1.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from jax-lnn==0.1.0) (0.13.2)\n",
            "Collecting torch>=2.10.0 (from jax-lnn==0.1.0)\n",
            "  Downloading torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (31 kB)\n",
            "Requirement already satisfied: xarray>=2025.12.0 in /usr/local/lib/python3.12/dist-packages (from jax-lnn==0.1.0) (2025.12.0)\n",
            "INFO: pip is looking at multiple versions of flax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting flax>=0.12.2 (from jax-lnn==0.1.0)\n",
            "  Downloading flax-0.12.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1.0) (1.1.2)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1.0) (0.11.32)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1.0) (0.1.80)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1.0) (13.9.4)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.2->jax-lnn==0.1.0) (0.1.10)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.2->jax-lnn==0.1.0) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.2->jax-lnn==0.1.0) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.2->jax-lnn==0.1.0) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1.0) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1.0) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.10.8->jax-lnn==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.20.1->jax-lnn==0.1.0) (5.29.5)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from onnx2pytorch>=0.5.3->jax-lnn==0.1.0) (0.24.0+cpu)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.23.2->jax-lnn==0.1.0) (25.12.19)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.23.2->jax-lnn==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from optax>=0.2.6->jax-lnn==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.12/dist-packages (from optax>=0.2.6->jax-lnn==0.1.0) (0.1.90)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn>=0.13.2->jax-lnn==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.10.0->jax-lnn==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.10.0->jax-lnn==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.10.0->jax-lnn==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.10.0->jax-lnn==0.1.0) (2025.3.0)\n",
            "Collecting cuda-bindings==12.9.4 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.4.5 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.6.0 (from torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting cuda-pathfinder~=1.1 (from cuda-bindings==12.9.4->torch>=2.10.0->jax-lnn==0.1.0)\n",
            "  Downloading cuda_pathfinder-1.3.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.87->optax>=0.2.6->jax-lnn==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1.0) (1.13.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1.0) (1.6.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1.0) (24.1.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1.0) (3.20.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn>=0.13.2->jax-lnn==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn>=0.13.2->jax-lnn==0.1.0) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.10.8->jax-lnn==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax>=0.12.2->jax-lnn==0.1.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax>=0.12.2->jax-lnn==0.1.0) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.23.2->jax-lnn==0.1.0) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision>=0.9.0 (from onnx2pytorch>=0.5.3->jax-lnn==0.1.0)\n",
            "  Downloading torchvision-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.10.0->jax-lnn==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.12.2->jax-lnn==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1.0) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.12.2->jax-lnn==0.1.0) (3.23.0)\n",
            "Downloading flax-0.12.2-py3-none-any.whl (488 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m488.0/488.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.9.0.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.9.0.1-cp312-cp312-manylinux_2_27_x86_64.whl (80.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.3/80.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx2pytorch-0.5.3-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (915.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m915.7/915.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (139.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.1/139.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cuda_pathfinder-1.3.3-py3-none-any.whl (27 kB)\n",
            "Building wheels for collected packages: jax-lnn, orbax\n",
            "  Building wheel for jax-lnn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax-lnn: filename=jax_lnn-0.1.0-py3-none-any.whl size=50017 sha256=2f2a20917283eb84fa32776625c3bd924074245bc303e723e6a0685f8ea105a4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2shzel_6/wheels/e4/73/e2/53d463a119e4252930e9bea05cfd1d7013a414201220cab8a8\n",
            "  Building wheel for orbax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for orbax: filename=orbax-0.1.9-py3-none-any.whl size=1496 sha256=e9d82a23fe12a57f4014c0c76133de882111c020dc2756ea2bc727d2e6e72b1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/93/1e/1d353609083480a258a14db334d1c16aefa65d30440035b8fd\n",
            "Successfully built jax-lnn orbax\n",
            "Installing collected packages: nvidia-cusparselt-cu12, triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, cuda-pathfinder, onnxruntime, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, cuda-bindings, onnx, nvidia-cusolver-cu12, matplotlib, jaxlib, torch, jax, torchvision, orbax, onnx2pytorch, flax, jax-lnn\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.29.2\n",
            "    Uninstalling nvidia-nccl-cu12-2.29.2:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.29.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.7.2\n",
            "    Uninstalling jaxlib-0.7.2:\n",
            "      Successfully uninstalled jaxlib-0.7.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cpu\n",
            "    Uninstalling torch-2.9.0+cpu:\n",
            "      Successfully uninstalled torch-2.9.0+cpu\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.7.2\n",
            "    Uninstalling jax-0.7.2:\n",
            "      Successfully uninstalled jax-0.7.2\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cpu\n",
            "    Uninstalling torchvision-0.24.0+cpu:\n",
            "      Successfully uninstalled torchvision-0.24.0+cpu\n",
            "  Attempting uninstall: flax\n",
            "    Found existing installation: flax 0.11.2\n",
            "    Uninstalling flax-0.11.2:\n",
            "      Successfully uninstalled flax-0.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.2 which is incompatible.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.10.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.2 which is incompatible.\n",
            "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cuda-bindings-12.9.4 cuda-pathfinder-1.3.3 flax-0.12.2 jax-0.9.0.1 jax-lnn-0.1.0 jaxlib-0.9.0.1 matplotlib-3.10.8 numpy-2.4.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.4.5 nvidia-nvtx-cu12-12.8.90 onnx-1.20.1 onnx2pytorch-0.5.3 onnxruntime-1.24.1 orbax-0.1.9 torch-2.10.0 torchvision-0.25.0 triton-3.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              },
              "id": "7cdddc088bbe4c8f8861559093c26b3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Requirement already satisfied: jax[cuda12_pip] in /usr/local/lib/python3.12/dist-packages (0.9.0.1)\n",
            "\u001b[33mWARNING: jax 0.9.0.1 does not provide the extra 'cuda12-pip'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: jaxlib<=0.9.0.1,>=0.9.0.1 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (0.9.0.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (0.5.4)\n",
            "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (2.4.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12_pip]) (1.16.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAX_PLATFORMS\"] = \"cpu\""
      ],
      "metadata": {
        "id": "o0US-jbrybAN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Library imports***"
      ],
      "metadata": {
        "id": "P8qVkwTrMmLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax import nnx\n",
        "from jlnn.symbolic.compiler import LNNFormula\n",
        "from jlnn.nn.constraints import apply_constraints\n",
        "from jlnn.training.losses import total_lnn_loss, logical_mse_loss, contradiction_loss\n",
        "from jlnn.storage.checkpoints import save_checkpoint, load_checkpoint\n",
        "import optax"
      ],
      "metadata": {
        "id": "wdBgoJHpMuVi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"JLNN loaded. JAX version:\", jax.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D9JyTUEwWGl",
        "outputId": "d0c9de49-4114-4f20-ee85-6a517c81a9dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JLNN loaded. JAX version: 0.9.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. MODEL DEFINITION***\n",
        "\n"
      ],
      "metadata": {
        "id": "wdrGqxrts-Et"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize random numbers for gate weights"
      ],
      "metadata": {
        "id": "kH5KWnVpwhbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rngs = nnx.Rngs(42)"
      ],
      "metadata": {
        "id": "h3v_kQLKwmvW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a model with a simple rule\n",
        "\n",
        "#### Formula definition:"
      ],
      "metadata": {
        "id": "4o3ZHjUatT8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "formula = \"0.8::A & B -> C\""
      ],
      "metadata": {
        "id": "YkhDc7-YtvJ0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model creation - this internally calls JLNNCompiler and builds the graph"
      ],
      "metadata": {
        "id": "RXQi0v4ltz1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LNNFormula(formula, rngs)\n",
        "print(f\"ğŸ§© Model compiled for formula: {formula}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj2Lx3STu3WV",
        "outputId": "96eb2afc-068a-4f6a-f9b1-d81cd039fd3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§© Model compiled for formula: 0.8::A & B -> C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***3. DATA PREPARATION***\n",
        "\n",
        "#### Inputs for JLNN must include grounding for all symbols in the formula (including C)<br>\n",
        "#### Format: [Lower Bound, Upper Bound] or [Value] for LearnedPredicate, batch size 1"
      ],
      "metadata": {
        "id": "j4BNhnCJ-Ilf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"A\": jnp.array([[0.9]]),\n",
        "    \"B\": jnp.array([[0.7]]),\n",
        "    \"C\": jnp.array([[0.5]])   # MANDATORY â€“ consequent must have grounding!\n",
        "}"
      ],
      "metadata": {
        "id": "j58eWarO-QtQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Target interval â€“ we want to learn `C â‰ˆ [0.6, 0.85]`"
      ],
      "metadata": {
        "id": "A2_qUoo--se-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = jnp.array([[0.6, 0.85]])"
      ],
      "metadata": {
        "id": "BpzLcZeqLGkV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### View initial prediction"
      ],
      "metadata": {
        "id": "8Dhsw7IJSJGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_pred = model(inputs)\n",
        "print(f\"Initial prediction (before training): {initial_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWEmRv-eSLBC",
        "outputId": "1b867187-bfdb-4b5e-8523-f3e8d9fefbaa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial prediction (before training): [[1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. NaN-PROTECTED TRAINING + DEBUG OUTPUTS***"
      ],
      "metadata": {
        "id": "EwTETjEZTzvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss function â€“ global, pure (JAX sees it as static)"
      ],
      "metadata": {
        "id": "B8LXeQzZzzy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(model, inputs, target):\n",
        "    pred = model(inputs)\n",
        "    pred = jnp.nan_to_num(pred, nan=0.5, posinf=1.0, neginf=0.0)  # protection against NaN\n",
        "    return total_lnn_loss(pred, target)"
      ],
      "metadata": {
        "id": "J9AiR6tAzNPi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizer definition with gradient clipping and lower LR for stability"
      ],
      "metadata": {
        "id": "kj4i0DTaUguG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = nnx.Optimizer(\n",
        "    model,\n",
        "    wrt=nnx.Param,\n",
        "    tx=optax.chain(\n",
        "        optax.clip_by_global_norm(1.0),\n",
        "        optax.adam(learning_rate=0.001)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "zTPb38sRrHvf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definition of training function"
      ],
      "metadata": {
        "id": "kt93T8egVOMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@nnx.jit\n",
        "def train_step(model, optimizer, inputs, target):\n",
        "    # Gradients to the model â€“ closure is traceable (inputs/target are arrays)\n",
        "    grads = nnx.grad(lambda m: loss_fn(m, inputs, target))(model)\n",
        "\n",
        "    # Loss before update (for debug)\n",
        "    loss = loss_fn(model, inputs, target)\n",
        "\n",
        "    optimizer.update(model, grads)\n",
        "    apply_constraints(model)\n",
        "\n",
        "    final_loss = loss_fn(model, inputs, target)\n",
        "    final_pred = model(inputs)\n",
        "\n",
        "    return loss, final_loss, final_pred"
      ],
      "metadata": {
        "id": "lZ_De9SUTvI_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Starting a workout"
      ],
      "metadata": {
        "id": "bwXtrLFAfgZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Starting training ===\")\n",
        "steps = 50\n",
        "for step in range(steps):\n",
        "    loss, final_loss, pred = train_step(model, optimizer, inputs, target)\n",
        "\n",
        "    print(f\"Step {step:3d} | Loss before/after constraints: {loss:.6f} â†’ {final_loss:.6f}\")\n",
        "    print(f\"Prediction: {pred}\")\n",
        "    print(\"â”€\" * 60)\n",
        "\n",
        "    if jnp.isnan(final_loss).any():\n",
        "        print(\"âŒ NaN detected! Stopping.\")\n",
        "        break\n",
        "\n",
        "print(\"=== Training completed ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DUWk0WUTvNW",
        "outputId": "0d3ed28c-e1bc-4e61-beb5-d12dfb70b037"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Starting training ===\n",
            "Step   0 | Loss before/after constraints: 0.091250 â†’ 0.090105\n",
            "Prediction: [[0.99750346 0.99900097]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step   1 | Loss before/after constraints: 0.090105 â†’ 0.089057\n",
            "Prediction: [[0.9952188  0.99803764]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step   2 | Loss before/after constraints: 0.089057 â†’ 0.087978\n",
            "Prediction: [[0.99284816 0.99705976]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step   3 | Loss before/after constraints: 0.087978 â†’ 0.086890\n",
            "Prediction: [[0.9904376 0.9960748]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step   4 | Loss before/after constraints: 0.086890 â†’ 0.085800\n",
            "Prediction: [[0.98800725 0.9950865 ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step   5 | Loss before/after constraints: 0.085800 â†’ 0.084713\n",
            "Prediction: [[0.98556733 0.9940971 ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step   6 | Loss before/after constraints: 0.084713 â†’ 0.083632\n",
            "Prediction: [[0.98312396 0.99310803]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step   7 | Loss before/after constraints: 0.083632 â†’ 0.082558\n",
            "Prediction: [[0.98068106 0.99212015]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step   8 | Loss before/after constraints: 0.082558 â†’ 0.081493\n",
            "Prediction: [[0.97824144 0.9911342 ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step   9 | Loss before/after constraints: 0.081493 â†’ 0.080437\n",
            "Prediction: [[0.97580713 0.9901507 ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  10 | Loss before/after constraints: 0.080437 â†’ 0.079390\n",
            "Prediction: [[0.9733797 0.98917  ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  11 | Loss before/after constraints: 0.079390 â†’ 0.078354\n",
            "Prediction: [[0.9709601 0.9881925]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  12 | Loss before/after constraints: 0.078354 â†’ 0.077329\n",
            "Prediction: [[0.9685495 0.9872184]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  13 | Loss before/after constraints: 0.077329 â†’ 0.076314\n",
            "Prediction: [[0.9661487 0.9862481]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  14 | Loss before/after constraints: 0.076314 â†’ 0.075311\n",
            "Prediction: [[0.96375835 0.98528165]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  15 | Loss before/after constraints: 0.075311 â†’ 0.074318\n",
            "Prediction: [[0.9613792 0.9843194]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  16 | Loss before/after constraints: 0.074318 â†’ 0.073337\n",
            "Prediction: [[0.9590116 0.9833614]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  17 | Loss before/after constraints: 0.073337 â†’ 0.072368\n",
            "Prediction: [[0.95665604 0.98240787]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  18 | Loss before/after constraints: 0.072368 â†’ 0.071410\n",
            "Prediction: [[0.954313  0.9814589]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  19 | Loss before/after constraints: 0.071410 â†’ 0.070463\n",
            "Prediction: [[0.95198274 0.98051476]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  20 | Loss before/after constraints: 0.070463 â†’ 0.069528\n",
            "Prediction: [[0.94966555 0.97957546]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  21 | Loss before/after constraints: 0.069528 â†’ 0.068604\n",
            "Prediction: [[0.94736177 0.9786411 ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  22 | Loss before/after constraints: 0.068604 â†’ 0.067692\n",
            "Prediction: [[0.9450716 0.9777117]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  23 | Loss before/after constraints: 0.067692 â†’ 0.066792\n",
            "Prediction: [[0.9427953 0.9767875]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  24 | Loss before/after constraints: 0.066792 â†’ 0.065903\n",
            "Prediction: [[0.94053286 0.97586846]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  25 | Loss before/after constraints: 0.065903 â†’ 0.065025\n",
            "Prediction: [[0.93828464 0.9749546 ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  26 | Loss before/after constraints: 0.065025 â†’ 0.064159\n",
            "Prediction: [[0.93605083 0.9740461 ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  27 | Loss before/after constraints: 0.064159 â†’ 0.063304\n",
            "Prediction: [[0.93383133 0.97314304]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  28 | Loss before/after constraints: 0.063304 â†’ 0.062460\n",
            "Prediction: [[0.93162644 0.9722454 ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  29 | Loss before/after constraints: 0.062460 â†’ 0.061627\n",
            "Prediction: [[0.9294361 0.9713532]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  30 | Loss before/after constraints: 0.061627 â†’ 0.060806\n",
            "Prediction: [[0.92726046 0.97046643]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  31 | Loss before/after constraints: 0.060806 â†’ 0.059995\n",
            "Prediction: [[0.9250995  0.96958524]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  32 | Loss before/after constraints: 0.059995 â†’ 0.059195\n",
            "Prediction: [[0.92295337 0.96870965]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  33 | Loss before/after constraints: 0.059195 â†’ 0.058406\n",
            "Prediction: [[0.92082196 0.96783954]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  34 | Loss before/after constraints: 0.058406 â†’ 0.057628\n",
            "Prediction: [[0.91870546 0.96697515]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  35 | Loss before/after constraints: 0.057628 â†’ 0.056860\n",
            "Prediction: [[0.91660374 0.9661163 ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  36 | Loss before/after constraints: 0.056860 â†’ 0.056103\n",
            "Prediction: [[0.9145168  0.96526307]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  37 | Loss before/after constraints: 0.056103 â†’ 0.055356\n",
            "Prediction: [[0.9124446 0.9644153]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  38 | Loss before/after constraints: 0.055356 â†’ 0.054620\n",
            "Prediction: [[0.9103872 0.9635733]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  39 | Loss before/after constraints: 0.054620 â†’ 0.053893\n",
            "Prediction: [[0.9083445  0.96273685]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  40 | Loss before/after constraints: 0.053893 â†’ 0.053176\n",
            "Prediction: [[0.90631646 0.9619059 ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  41 | Loss before/after constraints: 0.053176 â†’ 0.052470\n",
            "Prediction: [[0.9043031  0.96108055]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  42 | Loss before/after constraints: 0.052470 â†’ 0.051773\n",
            "Prediction: [[0.90230423 0.9602608 ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  43 | Loss before/after constraints: 0.051773 â†’ 0.051085\n",
            "Prediction: [[0.90031976 0.95944655]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  44 | Loss before/after constraints: 0.051085 â†’ 0.050407\n",
            "Prediction: [[0.8983498 0.9586378]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  45 | Loss before/after constraints: 0.050407 â†’ 0.049739\n",
            "Prediction: [[0.89639425 0.9578346 ]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  46 | Loss before/after constraints: 0.049739 â†’ 0.049080\n",
            "Prediction: [[0.894453   0.95703685]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  47 | Loss before/after constraints: 0.049080 â†’ 0.048430\n",
            "Prediction: [[0.89252573 0.95624447]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  48 | Loss before/after constraints: 0.048430 â†’ 0.047789\n",
            "Prediction: [[0.8906128  0.95545757]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Step  49 | Loss before/after constraints: 0.047789 â†’ 0.047156\n",
            "Prediction: [[0.8887138 0.9546761]]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "=== Training completed ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. RESULT AFTER TRAINING***"
      ],
      "metadata": {
        "id": "aHMFKQb4jzhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_pred = model(inputs)\n",
        "print(\"\\nFinal prediction after training:\")\n",
        "print(final_pred)\n",
        "\n",
        "print(f\"\\nTarget interval: {target}\")\n",
        "print(f\"Final loss: {total_lnn_loss(final_pred, target):.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RK-3bzAkR9S",
        "outputId": "2b534963-149f-49e5-c146-a9ad28f59b96"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final prediction after training:\n",
            "[[0.8887138 0.9546761]]\n",
            "\n",
            "Target interval: [[0.6  0.85]]\n",
            "Final loss: 0.047156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. CHECKPOINT â€“ SAVE AND LOAD (VERIFY)***"
      ],
      "metadata": {
        "id": "VjMn6WZqmEpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the trained model"
      ],
      "metadata": {
        "id": "jpkIRf5_m09x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_checkpoint(model, \"trained_model.ckpt.pkl\")\n",
        "print(\"Model saved as trained_model.ckpt.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij4RhMNMm6SA",
        "outputId": "84711970-89ec-452f-8035-3fe0af601ae9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved successfully: trained_model.ckpt.pkl\n",
            "Model saved as trained_model.ckpt.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new model instance (different seed â†’ different starting weights)"
      ],
      "metadata": {
        "id": "tuzu4EAEm7oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = LNNFormula(\"0.8::A & B -> C\", nnx.Rngs(999))"
      ],
      "metadata": {
        "id": "iknEG5dGnC2A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load checkpoint"
      ],
      "metadata": {
        "id": "CakT7q1jnHcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_checkpoint(new_model, \"trained_model.ckpt.pkl\")\n",
        "print(\"Checkpoint loaded into a new model instance.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bvRv1LznL_R",
        "outputId": "fa6ffd42-3cb6-439b-a1b0-b6bda7a662f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters successfully restored from: trained_model.ckpt.pkl\n",
            "Checkpoint loaded into a new model instance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verification â€“ the prediction should be the same as the original model"
      ],
      "metadata": {
        "id": "yRuYqatNnZ8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPrediction after loading checkpoint:\")\n",
        "print(new_model(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2Jf7gIVndOJ",
        "outputId": "a76177a5-db3a-45b5-ddd2-fea5516f2ed6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction after loading checkpoint:\n",
            "[[0.8887138 0.9546761]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nOriginal prediction (for comparison):\")\n",
        "print(model(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_90Mw3rymjy6",
        "outputId": "af410864-e2a8-418c-d58a-66952b40e18c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original prediction (for comparison):\n",
            "[[0.8887138 0.9546761]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***SUMMARY***\n",
        "\n",
        "- The model learned to approximate the target interval [0.6, 0.85] for C.\n",
        "- Training was done without NaN thanks to clipping and correct LR.\n",
        "- Checkpoint works â€“ the loaded instance gives the same output.\n",
        "- Next steps: experiment with different rules, larger batch, temporal operators (G/F/X)."
      ],
      "metadata": {
        "id": "-iiluIBnob9V"
      }
    }
  ]
}